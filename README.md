# Project Description
This ROS 2 project implements a Pepsi can trash collector. The robot first searches for a Pepsi can, then navigates towards it to grab it. Once the can is secured, the robot searches for a QR code placed above a disposal hole. Upon locating the QR code, the robot approaches it and drops the can into the hole. To assist the robot in recognizing its arrival at the hole, a strip of black tape is placed in front of it. When the robot reaches the hole, light sensors beneath the robot detect the black strip, signaling the robot to release the can. 

## Functionalities:
1. Perception:
- Can_detector: In this node we used a machine learning model to allow the robot to detect pepsi cans using its camera.
- QR_detector: In this node we wrote the code that allow the robot to detect the QR code. 
- Note that in both the can and QR detection code we are sending the centroid coordinates of their bounding boxes as outputs so that they can be used in the navigation code to center the robot to both the can and QR code. 

2. Navigation:
- Can_navigation: In this node we will use the centroid output generated by the can detector to first center the robot to the can and then move towards it. Once the robot approaches the can it will gradually slow down until it reaches a complete halt once it is 6cm away from the can.
- QR_navigation: In this node we will use the centroid output generated by the QR detector to first center the robot to the QR code and then move towards it. The robot will keep moving forward until it detects the black strip near the hole. 

3. Control:
- Gripper_action_client: In this node we generated a client for an already existing action node that controls the gripper of the robot. This client sends a request to the action node once it reaches the can so that it can grab it and then it send a cancel request once it reaches the hole so that it drops it.

4. Behavior Tree: 
- The whole logic of this project is controled by a behavior tree. First, the behavior tree calls the can detection and can navigation nodes so that the robot can navigate to the pepsi can. After it successfully arrives at the can the gripper client will send a request to close the gripper. Then the QR detection and navigation will start running so that the robot reaches the hole in front of the QR code. And finally, after the light sensors detects the black strip the robot will stop and the gripper client will send a cancel request to the gripper action so that the gripper opens and the can drops inside the hole.

## Building and Running the project:
To build and run the project on any device, Docker images were created. Here are the steps to build and run the image:

- Build The Base Image (build once):
```bash
sudo docker build -t ros_galactic_with_deps -f Dockerfile.base .
```

- To Build the Pip Image: 
```bash
sudo docker build -t ros_galactic_with_pip -f Dockerfile.pip .
```

- To Build the custom image (takes less time):
```bash
sudo docker build -t my_ros2_application .
```

- To Run the container:
```bash
sudo docker run --network host -it my_ros2_application 
```
or

```bash
sudo docker run -it my_ros2_application /bin/bash (to interact with the container)
```

## Authors:
- Razan Hmede
- Mohamad Nasser
- Johnny Hanna
